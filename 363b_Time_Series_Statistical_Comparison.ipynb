{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOsXGJ5shCoegEhNmo8+uTB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bnsreenu/python_for_microscopists/blob/master/363b_Time_Series_Statistical_Comparison.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://youtu.be/ubItfMWR9aw"
      ],
      "metadata": {
        "id": "1epc15nCHXX6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Time Series Statistical Comparison: Handling Temporal Autocorrelation\n",
        "\n",
        "## The Problem\n",
        "Traditional statistical tests (like Mann-Whitney U) assume data points are independent. However, time series data violates this assumption because:\n",
        "- Today's stock price depends on yesterday's price\n",
        "- Observations close in time are more similar than distant ones\n",
        "- This temporal autocorrelation can lead to incorrect statistical conclusions\n",
        "\n",
        "## What We'll Learn\n",
        "This notebook demonstrates 4 different approaches to compare two time series while properly handling temporal dependence:\n",
        "\n",
        "### 1. **Naive Approach** (What NOT to do)\n",
        "- Apply standard Mann-Whitney U test directly\n",
        "- Problem: Ignores temporal correlation, may give false results\n",
        "\n",
        "### 2. **Pre-whitening**\n",
        "- Remove temporal correlation first using ARIMA models\n",
        "- Compare the \"cleaned\" residuals\n",
        "- Idea: If we remove the time pattern, we can use standard tests\n",
        "\n",
        "### 3. **Dynamic Time Warping (DTW)**\n",
        "- Aligns two time series optimally before comparison\n",
        "- **Simple explanation**: Imagine stretching/compressing one series to best match the other\n",
        "- Useful when series have similar patterns but different timing\n",
        "\n",
        "### 4. **Block Bootstrap**\n",
        "- Resampling method that preserves temporal correlation structure\n",
        "- Idea: Instead of shuffling individual points, shuffle blocks of consecutive points\n",
        "- Maintains the \"memory\" in the data while testing significance\n",
        "\n",
        "## Our Example: AAPL vs MSFT Stock Returns\n",
        "We'll compare Apple and Microsoft daily stock returns to answer:\n",
        "- Are their return distributions significantly different?\n",
        "- How do different methods handle the temporal correlation in stock prices?\n",
        "- When do the methods agree vs disagree?\n",
        "\n",
        "\n",
        "## Expected Outcome\n",
        "Since AAPL and MSFT are both large tech stocks, we expect:\n",
        "- High correlation between their returns\n",
        "- Possible temporal autocorrelation in individual series\n",
        "- Methods may show **no significant difference** (which is a valid scientific result!)\n",
        "- Demonstrates importance of choosing appropriate comparison pairs\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "4bCgwoKD3Asw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install yfinance dtaidistance statsmodels"
      ],
      "metadata": {
        "id": "QRmjnFVp0zLJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "from scipy.stats import mannwhitneyu\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "from statsmodels.tsa.stattools import adfuller, acf\n",
        "from dtaidistance import dtw\n",
        "import yfinance as yf\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set plotting style\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams['figure.figsize'] = (14, 8)\n",
        "plt.rcParams['font.size'] = 11"
      ],
      "metadata": {
        "id": "wnanDGZj01sM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "##1. Data Loading & Visualization\n",
        "**Process:**\n",
        "1. Download AAPL and MSFT stock prices from Yahoo Finance\n",
        "2. Calculate daily returns (percentage changes)\n",
        "3. Create visualizations to explore the data\n",
        "\n",
        "**Key Insight:** High correlation (0.685) and similar distributions suggest these stocks move together - setting expectation for \"no significant difference\" result.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "px_9LvIgMgjZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download stock data\n",
        "print(\"Downloading stock data...\")\n",
        "tickers = ['AAPL', 'MSFT']\n",
        "data = yf.download(tickers, start='2022-01-01', end='2024-12-01')['Close']\n",
        "data = data.dropna()\n",
        "\n",
        "# Calculate returns for better stationarity\n",
        "returns = data.pct_change().dropna() * 100  # Convert to percentage\n",
        "prices = data.copy()\n",
        "\n",
        "\n",
        "print(f\"Data shape: {data.shape}\")\n",
        "print(f\"Date range: {data.index[0].date()} to {data.index[-1].date()}\")\n",
        "print(f\"Total observations: {len(data)}\")\n",
        "\n",
        "# Basic visualization\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "# Plot prices\n",
        "axes[0,0].plot(prices.index, prices['AAPL'], label='AAPL', alpha=0.8)\n",
        "axes[0,0].plot(prices.index, prices['MSFT'], label='MSFT', alpha=0.8)\n",
        "axes[0,0].set_title('Stock Prices')\n",
        "axes[0,0].set_ylabel('Price ($)')\n",
        "axes[0,0].legend()\n",
        "\n",
        "# Plot returns\n",
        "axes[0,1].plot(returns.index, returns['AAPL'], label='AAPL', alpha=0.7)\n",
        "axes[0,1].plot(returns.index, returns['MSFT'], label='MSFT', alpha=0.7)\n",
        "axes[0,1].set_title('Daily Returns (%)')\n",
        "axes[0,1].set_ylabel('Return (%)')\n",
        "axes[0,1].legend()\n",
        "\n",
        "# Correlation plot\n",
        "axes[1,0].scatter(returns['AAPL'], returns['MSFT'], alpha=0.6)\n",
        "correlation = returns['AAPL'].corr(returns['MSFT'])   # Pearson paiwise correlation\n",
        "axes[1,0].set_xlabel('AAPL Returns (%)')\n",
        "axes[1,0].set_ylabel('MSFT Returns (%)')\n",
        "axes[1,0].set_title(f'Returns Correlation (r = {correlation:.3f})')\n",
        "\n",
        "# Distribution comparison\n",
        "axes[1,1].hist(returns['AAPL'], bins=30, alpha=0.7, label='AAPL', density=True)\n",
        "axes[1,1].hist(returns['MSFT'], bins=30, alpha=0.7, label='MSFT', density=True)\n",
        "axes[1,1].set_xlabel('Returns (%)')\n",
        "axes[1,1].set_ylabel('Density')\n",
        "axes[1,1].set_title('Return Distributions')\n",
        "axes[1,1].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UhVsYC4B04M1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2: Autocorrelation Check\n",
        "**Process:**\n",
        "1. Apply Ljung-Box test to detect temporal correlation. Basically, test whether a series of observations over time are random and independent\n",
        "2. Plot autocorrelation functions (ACF) for visual inspection. Note that autocorrelation refers to the measure of similarity between a time series and a lagged version of itself over successive time intervals.\n",
        "3. Determine if standard tests might be biased\n",
        "\n",
        "**Key Insight:** MSFT shows significant autocorrelation (p=0.025) while AAPL doesn't (p=0.626), despite visually similar ACF plots. This mixed result makes it perfect for comparing methods.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "-ch4hJYoMtJL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def check_autocorrelation(series, name, max_lags=20):\n",
        "    \"\"\"Check for temporal autocorrelation in a time series\"\"\"\n",
        "    print(f\"\\n=== Autocorrelation Analysis: {name} ===\")\n",
        "\n",
        "    # Ljung-Box test for autocorrelation\n",
        "    from statsmodels.stats.diagnostic import acorr_ljungbox\n",
        "    lb_stat = acorr_ljungbox(series, lags=10, return_df=True)\n",
        "\n",
        "    print(f\"Ljung-Box test p-value (lag 10): {lb_stat['lb_pvalue'].iloc[-1]:.4f}\")\n",
        "    if lb_stat['lb_pvalue'].iloc[-1] < 0.05:\n",
        "        print(\"-> Autocorrelation detected\")\n",
        "    else:\n",
        "        print(\"-> No significant autocorrelation\")\n",
        "\n",
        "    # Plot ACF\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "    # Autocorrelation function\n",
        "    autocorr = acf(series, nlags=max_lags, alpha=0.05)\n",
        "    lags = range(len(autocorr[0]))\n",
        "    ax1.plot(lags, autocorr[0], 'bo-', markersize=4)\n",
        "    ax1.fill_between(lags, autocorr[1][:, 0], autocorr[1][:, 1], alpha=0.3)\n",
        "    ax1.axhline(0, color='black', linestyle='--', alpha=0.8)\n",
        "    ax1.set_title(f'Autocorrelation Function: {name}')\n",
        "    ax1.set_xlabel('Lag')\n",
        "    ax1.set_ylabel('Autocorrelation')\n",
        "\n",
        "    # Time series plot\n",
        "    ax2.plot(series.index, series, alpha=0.8)\n",
        "    ax2.set_title(f'Time Series: {name}')\n",
        "    ax2.set_ylabel('Value')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return lb_stat['lb_pvalue'].iloc[-1] < 0.05\n",
        "\n",
        "# Check autocorrelation in returns\n",
        "AAPL_has_autocorr = check_autocorrelation(returns['AAPL'], 'AAPL Returns')\n",
        "MSFT_has_autocorr = check_autocorrelation(returns['MSFT'], 'MSFT Returns')"
      ],
      "metadata": {
        "id": "84qXS_p41EFY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3: Naive Comparison\n",
        "**Process:**\n",
        "1. Apply Mann-Whitney U test directly to original returns\n",
        "2. Ignore any temporal correlation structure\n",
        "3. Establish baseline comparison\n",
        "\n",
        "**Key Insight:** P-value = 0.921 (not significant). This is our \"what NOT to do\" baseline, though it may still give correct results when autocorrelation is mild.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "zfwZw6ZDM8zv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def naive_comparison(series1, series2, name1, name2):\n",
        "    \"\"\"Standard Mann-Whitney U test ignoring temporal structure\"\"\"\n",
        "    print(f\"\\n=== Naive Comparison: {name1} vs {name2} ===\")\n",
        "\n",
        "    # Mann-Whitney U test\n",
        "    stat, p_value = mannwhitneyu(series1, series2, alternative='two-sided')\n",
        "\n",
        "    # Basic statistics\n",
        "    print(f\"{name1}: Mean = {series1.mean():.3f}, Std = {series1.std():.3f}\")\n",
        "    print(f\"{name2}: Mean = {series2.mean():.3f}, Std = {series2.std():.3f}\")\n",
        "    print(f\"Mann-Whitney U statistic: {stat:.2f}\")\n",
        "    print(f\"P-value: {p_value:.6f}\")\n",
        "    print(f\"Result: {'Significantly different' if p_value < 0.05 else 'Not significantly different'}\")\n",
        "\n",
        "    return p_value\n",
        "\n",
        "naive_p = naive_comparison(returns['AAPL'], returns['MSFT'], 'AAPL', 'MSFT')"
      ],
      "metadata": {
        "id": "7fXodLgA1Lbj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4: Pre-whitening Approach\n",
        "**Process:**\n",
        "1. Fit ARIMA(1,0,0) models to remove temporal correlation. Note that ARIMA(1,0,0) is a first-order autoregressive model. It predicts future values of a time series based on a linear combination of its previous value and a constant, plus a random error term.\n",
        "2. Extract residuals (cleaned data with correlation removed)\n",
        "3. Apply Mann-Whitney U test to residuals\n",
        "4. Check if residuals are truly white noise\n",
        "\n",
        "**Key Insight:** P-value = 0.882 (not significant). Since original autocorrelation was weak (AR coefficients ~0.01), pre-whitening had minimal impact on results.\n",
        "\n",
        "**In summary** - After removing the temporal correlation patterns (pre-whitening), we will find that the \"cleaned\" return data from AAPL and MSFT look statistically indistinguishable.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "KtVT95seNH0v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def prewhiten_series(series, name):\n",
        "    \"\"\"Remove temporal correlation using ARIMA modeling\"\"\"\n",
        "    print(f\"\\n=== Pre-whitening: {name} ===\")\n",
        "\n",
        "    # Fit ARIMA(1,0,0) model - simple AR(1)\n",
        "    model = ARIMA(series, order=(1, 0, 0))\n",
        "    fitted = model.fit()\n",
        "\n",
        "    # Extract residuals\n",
        "    residuals = fitted.resid\n",
        "\n",
        "    print(f\"AR(1) coefficient: {fitted.params[1]:.4f}\")\n",
        "    print(f\"Residuals mean: {residuals.mean():.4f}\")\n",
        "    print(f\"Residuals std: {residuals.std():.4f}\")\n",
        "\n",
        "    # Check if residuals are white noise\n",
        "    from statsmodels.stats.diagnostic import acorr_ljungbox\n",
        "    lb_residuals = acorr_ljungbox(residuals, lags=10, return_df=True)\n",
        "    print(f\"Ljung-Box test on residuals p-value: {lb_residuals['lb_pvalue'].iloc[-1]:.4f}\")\n",
        "\n",
        "    return residuals, fitted\n",
        "\n",
        "# Pre-whiten both series\n",
        "AAPL_residuals, AAPL_model = prewhiten_series(returns['AAPL'], 'AAPL')\n",
        "MSFT_residuals, MSFT_model = prewhiten_series(returns['MSFT'], 'MSFT')"
      ],
      "metadata": {
        "id": "5f_jwiRm1P9q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare pre-whitened series\n",
        "def compare_prewhitened(resid1, resid2, name1, name2):\n",
        "    \"\"\"Compare pre-whitened residuals\"\"\"\n",
        "    print(f\"\\n=== Pre-whitened Comparison: {name1} vs {name2} ===\")\n",
        "\n",
        "    stat, p_value = mannwhitneyu(resid1, resid2, alternative='two-sided')\n",
        "\n",
        "    print(f\"Mann-Whitney U statistic: {stat:.2f}\")\n",
        "    print(f\"P-value: {p_value:.6f}\")\n",
        "    print(f\"Result: {'Significantly different' if p_value < 0.05 else 'Not significantly different'}\")\n",
        "\n",
        "    # Visualization\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "    # Time series of residuals\n",
        "    axes[0].plot(resid1.index, resid1, label=name1, alpha=0.7)\n",
        "    axes[0].plot(resid2.index, resid2, label=name2, alpha=0.7)\n",
        "    axes[0].set_title('Pre-whitened Residuals')\n",
        "    axes[0].set_ylabel('Residual')\n",
        "    axes[0].legend()\n",
        "\n",
        "    # Distribution comparison\n",
        "    axes[1].hist(resid1, bins=30, alpha=0.7, label=name1, density=True)\n",
        "    axes[1].hist(resid2, bins=30, alpha=0.7, label=name2, density=True)\n",
        "    axes[1].set_title('Residual Distributions')\n",
        "    axes[1].set_xlabel('Residual Value')\n",
        "    axes[1].set_ylabel('Density')\n",
        "    axes[1].legend()\n",
        "\n",
        "    # Box plot\n",
        "    box_data = pd.DataFrame({name1: resid1, name2: resid2})\n",
        "    axes[2].boxplot([resid1.dropna(), resid2.dropna()], labels=[name1, name2])\n",
        "    axes[2].set_title('Residual Box Plots')\n",
        "    axes[2].set_ylabel('Residual Value')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return p_value\n",
        "\n",
        "prewhitened_p = compare_prewhitened(AAPL_residuals, MSFT_residuals, 'AAPL', 'MSFT')\n"
      ],
      "metadata": {
        "id": "Z0QbEVfj1UUt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5: Dynamic Time Warping (DTW)\n",
        "**Process:**\n",
        "1. **Warp the time axis** - Find optimal alignment between series\n",
        "2. **Create aligned datasets** - Extract optimally matched data points  \n",
        "3. **Apply standard test** - Run Mann-Whitney U on aligned values\n",
        "4. Visualize the warping path and alignment results\n",
        "\n",
        "**Key Insight:** P-value = 0.618 (not significant). DTW improved correlation from 0.685 → 0.834, showing series are very similar when timing differences are removed. DTW is preprocessing, not a different statistical test.\n",
        "\n",
        "**Note:** DTW doesn't remove autocorrelation - it removes timing differences. We're testing whether the return magnitudes are different when patterns are optimally matched, regardless of autocorrelation.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "aWWEI3yyLnQL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dtw_comparison(series1, series2, name1, name2):\n",
        "    \"\"\"Compare time series using Dynamic Time Warping\"\"\"\n",
        "    print(f\"\\n=== DTW Analysis: {name1} vs {name2} ===\")\n",
        "\n",
        "    # Convert to numpy arrays and ensure they're clean\n",
        "    s1 = series1.dropna().values\n",
        "    s2 = series2.dropna().values\n",
        "\n",
        "    # Truncate to same length for fair comparison\n",
        "    min_len = min(len(s1), len(s2))\n",
        "    s1 = s1[:min_len]\n",
        "    s2 = s2[:min_len]\n",
        "\n",
        "    print(f\"Comparing series of length: {len(s1)}\")\n",
        "\n",
        "    # Calculate DTW distance\n",
        "    dtw_distance = dtw.distance(s1, s2)\n",
        "    print(f\"DTW Distance: {dtw_distance:.4f}\")\n",
        "\n",
        "    # Get optimal warping path\n",
        "    path = dtw.warping_path(s1, s2)\n",
        "\n",
        "    # Create DTW visualization\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "    # Original time series\n",
        "    axes[0,0].plot(range(len(s1)), s1, 'b-', label=name1, alpha=0.8)\n",
        "    axes[0,0].plot(range(len(s2)), s2, 'r-', label=name2, alpha=0.8)\n",
        "    axes[0,0].set_title('Original Time Series')\n",
        "    axes[0,0].set_ylabel('Value')\n",
        "    axes[0,0].legend()\n",
        "\n",
        "    # DTW path visualization (simplified)\n",
        "    # Create a manual distance matrix for visualization\n",
        "    n1, n2 = len(s1), len(s2)\n",
        "    dtw_matrix = np.zeros((n1, n2))\n",
        "\n",
        "    for i in range(n1):\n",
        "        for j in range(n2):\n",
        "            dtw_matrix[i, j] = abs(s1[i] - s2[j])\n",
        "\n",
        "    im = axes[0,1].imshow(dtw_matrix, cmap='viridis', aspect='auto')\n",
        "    axes[0,1].plot([p[1] for p in path], [p[0] for p in path], 'w-', linewidth=2)\n",
        "    axes[0,1].set_title('DTW Distance Matrix & Optimal Path')\n",
        "    axes[0,1].set_xlabel(f'{name2} Index')\n",
        "    axes[0,1].set_ylabel(f'{name1} Index')\n",
        "    plt.colorbar(im, ax=axes[0,1])\n",
        "\n",
        "    # Aligned series using DTW path\n",
        "    aligned_s1 = [s1[p[0]] for p in path]\n",
        "    aligned_s2 = [s2[p[1]] for p in path]\n",
        "\n",
        "    axes[1,0].plot(aligned_s1, 'b-', label=f'{name1} (aligned)', alpha=0.8)\n",
        "    axes[1,0].plot(aligned_s2, 'r-', label=f'{name2} (aligned)', alpha=0.8)\n",
        "    axes[1,0].set_title('DTW Aligned Series')\n",
        "    axes[1,0].set_ylabel('Value')\n",
        "    axes[1,0].legend()\n",
        "\n",
        "    # Scatter plot of aligned values\n",
        "    axes[1,1].scatter(aligned_s1, aligned_s2, alpha=0.6)\n",
        "    axes[1,1].plot([min(aligned_s1), max(aligned_s1)], [min(aligned_s1), max(aligned_s1)], 'r--')\n",
        "    correlation_aligned = np.corrcoef(aligned_s1, aligned_s2)[0,1]\n",
        "    axes[1,1].set_xlabel(f'{name1} (aligned)')\n",
        "    axes[1,1].set_ylabel(f'{name2} (aligned)')\n",
        "    axes[1,1].set_title(f'Aligned Values (r = {correlation_aligned:.3f})')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return dtw_distance, aligned_s1, aligned_s2\n",
        "\n",
        "# Apply DTW to returns\n",
        "dtw_dist, AAPL_aligned, MSFT_aligned = dtw_comparison(returns['AAPL'], returns['MSFT'], 'AAPL', 'MSFT')"
      ],
      "metadata": {
        "id": "qpod32ju1YmX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Note about the above Results:\n",
        "\n",
        "- White diagonal path shows optimal alignment between series - basically, the optimal warping path\n",
        "- Path stays close to diagonal = series already well-aligned in time (In other words, Both stocks move together on similar days)\n",
        "\n",
        "**Alignment Effect:**\n",
        "- Original correlation: 0.685\n",
        "- **After DTW alignment: 0.834** (significant improvement!)\n",
        "- DTW found subtle timing differences and corrected them\n",
        "\n",
        "**Key Takeaway:** DTW revealed that AAPL and MSFT have very similar patterns - they just don't always move on exactly the same days. This explains why the statistical test may find even fewer differences after alignment."
      ],
      "metadata": {
        "id": "QcOFJSnRTOSO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_dtw_aligned(aligned1, aligned2, name1, name2):\n",
        "    \"\"\"Compare DTW-aligned series\"\"\"\n",
        "    print(f\"\\n=== DTW-Aligned Comparison: {name1} vs {name2} ===\")\n",
        "\n",
        "    stat, p_value = mannwhitneyu(aligned1, aligned2, alternative='two-sided')\n",
        "\n",
        "    print(f\"Mann-Whitney U statistic: {stat:.2f}\")\n",
        "    print(f\"P-value: {p_value:.6f}\")\n",
        "    print(f\"Result: {'Significantly different' if p_value < 0.05 else 'Not significantly different'}\")\n",
        "\n",
        "    return p_value\n",
        "\n",
        "dtw_aligned_p = compare_dtw_aligned(AAPL_aligned, MSFT_aligned, 'AAPL', 'MSFT')"
      ],
      "metadata": {
        "id": "YyaS-rzr1lBM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Block Bootstrap\n",
        "\n",
        "**Process:**\n",
        "\n",
        "1. **Combine series data** - Concatenate AAPL and MSFT returns into one long series (since we're comparing overall distributions, not paired differences)\n",
        "2. **Resample in chunks** - Take consecutive blocks of 10 days (e.g., days 50-59, 200-209) with random starting positions\n",
        "3. **Preserve local correlation** - Don't shuffle individual points (breaks autocorrelation), shuffle blocks instead\n",
        "4. **Create bootstrap samples** - Combine blocks to make new time series of same length, split back into two groups\n",
        "5. **Calculate test statistic** - Find difference in means for each bootstrap sample (repeat 1000 times)\n",
        "6. **Build null distribution** - If no true difference exists, our observed difference should fall within this distribution\n",
        "7. **Compare observed to null** - Our actual difference (0.0024%) vs bootstrap distribution\n",
        "\n",
        "**Key Insight:** P-value = 0.990 (not significant). Our observed difference falls right in the center of what we'd expect by random chance, even accounting for temporal correlation. Most conservative method confirms conclusion with maximum confidence."
      ],
      "metadata": {
        "id": "LGAoZcBC9zTB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def block_bootstrap_test(series1, series2, name1, name2, block_size=10, n_bootstrap=1000):\n",
        "    \"\"\"Block bootstrap test preserving temporal correlation\"\"\"\n",
        "    print(f\"\\n=== Block Bootstrap Test: {name1} vs {name2} ===\")\n",
        "    print(f\"Block size: {block_size}, Bootstrap samples: {n_bootstrap}\")\n",
        "\n",
        "    # Original test statistic (difference in means)\n",
        "    original_diff = series1.mean() - series2.mean()\n",
        "    print(f\"Original mean difference: {original_diff:.4f}\")\n",
        "\n",
        "    # Combine series for bootstrap\n",
        "    combined = pd.concat([series1, series2])\n",
        "    n1, n2 = len(series1), len(series2)\n",
        "    n_total = len(combined)\n",
        "\n",
        "    bootstrap_diffs = []\n",
        "\n",
        "    for i in range(n_bootstrap):\n",
        "        # Generate bootstrap sample using block sampling\n",
        "        bootstrap_sample = []\n",
        "        current_pos = 0\n",
        "\n",
        "        while len(bootstrap_sample) < n_total:\n",
        "            # Random starting position\n",
        "            start = np.random.randint(0, n_total - block_size + 1)\n",
        "            block = combined.iloc[start:start + block_size].values\n",
        "            bootstrap_sample.extend(block)\n",
        "\n",
        "        # Trim to exact size\n",
        "        bootstrap_sample = bootstrap_sample[:n_total]\n",
        "\n",
        "        # Split into two groups\n",
        "        boot_group1 = bootstrap_sample[:n1]\n",
        "        boot_group2 = bootstrap_sample[n1:n1+n2]\n",
        "\n",
        "        # Calculate test statistic\n",
        "        boot_diff = np.mean(boot_group1) - np.mean(boot_group2)\n",
        "        bootstrap_diffs.append(boot_diff)\n",
        "\n",
        "    bootstrap_diffs = np.array(bootstrap_diffs)\n",
        "\n",
        "    # Calculate p-value (two-tailed)\n",
        "    p_value = 2 * min(np.mean(bootstrap_diffs >= original_diff),\n",
        "                      np.mean(bootstrap_diffs <= original_diff))\n",
        "\n",
        "    print(f\"Bootstrap p-value: {p_value:.4f}\")\n",
        "    print(f\"Result: {'Significantly different' if p_value < 0.05 else 'Not significantly different'}\")\n",
        "\n",
        "    # Visualization\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.hist(bootstrap_diffs, bins=50, alpha=0.7, density=True, color='lightblue')\n",
        "    plt.axvline(original_diff, color='red', linestyle='--', linewidth=2,\n",
        "                label=f'Observed difference: {original_diff:.4f}')\n",
        "    plt.axvline(0, color='black', linestyle='-', alpha=0.5, label='Null hypothesis')\n",
        "    plt.xlabel('Mean Difference')\n",
        "    plt.ylabel('Density')\n",
        "    plt.title(f'Block Bootstrap Distribution (p = {p_value:.4f})')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    return p_value\n",
        "\n",
        "block_bootstrap_p = block_bootstrap_test(returns['AAPL'], returns['MSFT'], 'AAPL', 'MSFT')"
      ],
      "metadata": {
        "id": "K81LHyyx1614"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 7: Final Comparison\n",
        "**Process:**\n",
        "1. Compare all four p-values side by side\n",
        "2. Evaluate method consistency and sensitivity\n",
        "3. Interpret results in context of detected autocorrelation\n",
        "\n",
        "**Key Insight:** All methods agree (no significant difference), building confidence in conclusion. DTW was most sensitive, block bootstrap most conservative. Method consistency validates that AAPL and MSFT truly have similar return distributions."
      ],
      "metadata": {
        "id": "Uxss9ZQgOOyI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VERK1QGN0fUE"
      },
      "outputs": [],
      "source": [
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"SUMMARY OF ALL APPROACHES\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "results_summary = pd.DataFrame({\n",
        "    'Method': ['Naive Mann-Whitney U', 'Pre-whitened Residuals', 'DTW Aligned', 'Block Bootstrap'],\n",
        "    'P-value': [naive_p, prewhitened_p, dtw_aligned_p, block_bootstrap_p],\n",
        "    'Significant': [p < 0.05 for p in [naive_p, prewhitened_p, dtw_aligned_p, block_bootstrap_p]]\n",
        "})\n",
        "\n",
        "print(results_summary.to_string(index=False))\n",
        "\n",
        "print(f\"\\nKey Insights:\")\n",
        "print(f\"- Temporal autocorrelation {'was' if AAPL_has_autocorr or MSFT_has_autocorr else 'was not'} detected\")\n",
        "print(f\"- DTW distance between series: {dtw_dist:.4f}\")\n",
        "print(f\"- Original correlation: {correlation:.3f}\")\n",
        "\n",
        "# Final visualization comparing all approaches\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "methods = results_summary['Method']\n",
        "p_values = results_summary['P-value']\n",
        "colors = ['red' if sig else 'gray' for sig in results_summary['Significant']]\n",
        "\n",
        "bars = ax.bar(methods, p_values, color=colors, alpha=0.7)\n",
        "ax.axhline(0.05, color='black', linestyle='--', label='α = 0.05')\n",
        "ax.set_ylabel('P-value')\n",
        "ax.set_title('Comparison of Statistical Test Results')\n",
        "ax.tick_params(axis='x', rotation=45)\n",
        "\n",
        "# Add p-value labels on bars\n",
        "for bar, p_val in zip(bars, p_values):\n",
        "    height = bar.get_height()\n",
        "    ax.text(bar.get_x() + bar.get_width()/2., height + 0.001,\n",
        "            f'{p_val:.4f}', ha='center', va='bottom')\n",
        "\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Final Summary: Method Comparison\n",
        "\n",
        "**Unanimous Agreement:** All four methods conclude no significant difference between AAPL and MSFT returns.\n",
        "\n",
        "**Method Rankings by Sensitivity:**\n",
        "1. **DTW Aligned** (p = 0.618) - Most sensitive after optimal alignment\n",
        "2. **Pre-whitened** (p = 0.882) - Slight improvement after removing autocorrelation  \n",
        "3. **Naive Mann-Whitney** (p = 0.921) - Simple approach worked well\n",
        "4. **Block Bootstrap** (p = 0.990) - Most conservative, accounts for correlation structure\n",
        "\n",
        "**Key Takeaways:**\n",
        "- **Method consistency builds confidence** - when all approaches agree, we trust the result\n",
        "- **Autocorrelation didn't bias results severely** - mild correlation (r=0.685) didn't mislead naive test\n",
        "- **\"No significant difference\" IS a valid scientific conclusion** - confirms these tech stocks behave similarly\n",
        "- **Sophisticated methods aren't always needed** - but checking multiple approaches is good practice\n",
        "\n",
        "**Real-World Insight:** AAPL and MSFT are so similar (same sector, market cap, economic drivers) that even advanced statistical methods can't find meaningful differences in their return patterns."
      ],
      "metadata": {
        "id": "kUytyYir-bCu"
      }
    }
  ]
}