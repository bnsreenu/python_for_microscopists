{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN3JluQmF4bX6xQMOdel+C+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bnsreenu/python_for_microscopists/blob/master/363_Comparing_Two_Groups_Non_parametric_Tests.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://youtu.be/sc2WN0AqhIc"
      ],
      "metadata": {
        "id": "dXnC3UUtYtJM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Comparing Two Groups: Non-parametric Tests\n",
        "**Part 5 of the Statistical Analysis in Python Tutorial Series**"
      ],
      "metadata": {
        "id": "5-ISHoSk3u6a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.formula.api import ols\n",
        "from statsmodels.stats.power import TTestIndPower, TTestPower\n",
        "import warnings\n",
        "from scipy.stats import chi2_contingency\n",
        "from scipy.stats import mannwhitneyu, wilcoxon, ranksums\n",
        "from scipy.stats import fisher_exact\n",
        "from scipy.stats import median_test\n",
        "from scipy.stats import binomtest  # For sign test\n",
        "\n",
        "# Suppress warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set visualization style consistent with previous tutorials\n",
        "sns.set(style=\"whitegrid\")\n",
        "plt.rcParams['figure.figsize'] = (12, 8)\n",
        "plt.rcParams['font.size'] = 12"
      ],
      "metadata": {
        "id": "8GNg-tB03z-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the UCI Heart Disease dataset\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data\"\n",
        "column_names = ['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg',\n",
        "                'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal', 'target']\n",
        "heart_data = pd.read_csv(url, names=column_names, na_values='?')\n",
        "\n",
        "# Display the first few rows of the dataset\n",
        "print(\"First 5 rows of the UCI Heart Disease dataset:\")\n",
        "print(heart_data.head())\n",
        "\n",
        "# Basic dataset information\n",
        "print(\"\\nDataset Information:\")\n",
        "heart_data.info()\n",
        "\n",
        "# Check for missing values\n",
        "print(\"\\nMissing values per column:\")\n",
        "print(heart_data.isnull().sum())\n",
        "\n",
        "# Replace missing values with the median for numerical columns\n",
        "heart_data = heart_data.fillna(heart_data.median())"
      ],
      "metadata": {
        "id": "SrauqObA33Mb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert target variable to binary (0 = no disease, 1 = disease)\n",
        "# Otherwise we have 1, 2, 3, 4 indicating severity. Lets us convert all these to just 1 - indicating the presence of the disease\n",
        "heart_data['target'] = heart_data['target'].apply(lambda x: 0 if x == 0 else 1)\n",
        "\n",
        "# Convert sex to categorical for better interpretability (0 = female, 1 = male)\n",
        "# Basically instead of 0 and 1 we will have Female and Male\n",
        "heart_data['sex'] = heart_data['sex'].map({0: 'Female', 1: 'Male'})\n",
        "\n",
        "# Basic statistics\n",
        "print(\"\\nBasic Statistical Summary:\")\n",
        "print(heart_data.describe())"
      ],
      "metadata": {
        "id": "9wR4C8Op35fM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Introduction to Non-parametric Tests\n",
        "\n",
        "## When to Use Non-parametric Tests\n",
        "\n",
        "Non-parametric tests are alternatives to parametric tests when one or more of the parametric test assumptions are violated. They're particularly useful in the following situations:\n",
        "\n",
        "1. **Violation of Normality Assumption:**\n",
        "   - When data is significantly skewed or has heavy tails\n",
        "   - When sample sizes are too small to rely on the Central Limit Theorem\n",
        "   - When data contains substantial outliers\n",
        "\n",
        "2. **Ordinal Data:**\n",
        "   - When data is measured on ordinal scales rather than interval/ratio scales\n",
        "   - When exact distances between values are not meaningful, but their ranks are\n",
        "\n",
        "3. **Small Sample Sizes:**\n",
        "   - When there are too few observations to confidently verify parametric assumptions\n",
        "   - When sample sizes are unequal between groups\n",
        "\n",
        "4. **Robustness:**\n",
        "   - When seeking results that are less sensitive to outliers\n",
        "   - When wanting to minimize assumptions about the underlying data distribution\n",
        "\n",
        "## Key Non-parametric Tests and Their Parametric Equivalents\n",
        "\n",
        "| Parametric Test | Non-parametric Alternative | Key Difference |\n",
        "|-----------------|---------------------------|---------------|\n",
        "| Independent t-test | Mann-Whitney U test | Compares distributions/ranks instead of means |\n",
        "| Paired t-test | Wilcoxon signed-rank test | Uses signed ranks of paired differences |\n",
        "| One-way ANOVA | Kruskal-Wallis H test | Compares ranks across multiple groups |\n",
        "| Pearson correlation | Spearman rank correlation | Correlates ranks instead of raw values |\n",
        "| Chi-square test | Fisher's exact test | Calculates exact probability rather than approximation |\n",
        "\n",
        "While non-parametric tests have fewer assumptions, they generally have less statistical power than their parametric counterparts when parametric assumptions are met. This means they may be less likely to detect a true effect. However, when assumptions are violated, non-parametric tests often outperform parametric tests in both power and Type I error control.\n"
      ],
      "metadata": {
        "id": "h2uyskrq36Kb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Testing for Normality: A Review\n",
        "\n",
        "Before deciding between parametric and non-parametric tests, we should test whether our data meets the normality assumption of parametric tests. We'll use both visual methods (histograms, Q-Q plots) and formal tests (Shapiro-Wilk test).\n"
      ],
      "metadata": {
        "id": "e3_lfW3A4EVy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def check_normality(data, variable_name=None, alpha=0.05):\n",
        "    \"\"\"\n",
        "    Check normality assumption using both visual methods and statistical tests.\n",
        "    \"\"\"\n",
        "    if variable_name is None:\n",
        "        variable_name = \"Variable\"\n",
        "\n",
        "    # Create figure with 2 subplots\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
        "\n",
        "    # Plot 1: Histogram with normal curve\n",
        "    sns.histplot(data, kde=True, ax=ax1)\n",
        "    ax1.set_title(f'Histogram of {variable_name}')\n",
        "\n",
        "    # Plot 2: Q-Q plot\n",
        "    #sm.qqplot(data, line='45', ax=ax2)\n",
        "    stats.probplot(data, dist=\"norm\", plot=ax2)\n",
        "    ax2.set_title(f'Q-Q Plot of {variable_name}')\n",
        "\n",
        "    # Adjust layout\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    ######## Perform Shapiro-Wilk test  ###############\n",
        "    shapiro_stat, shapiro_p = stats.shapiro(data)\n",
        "\n",
        "    # Print results\n",
        "    print(f\"Normality Check for {variable_name}:\")\n",
        "    print(f\"Shapiro-Wilk Test: Statistic = {shapiro_stat:.4f}, p-value = {shapiro_p:.6f}\")\n",
        "\n",
        "    if shapiro_p < alpha:\n",
        "        print(f\"Conclusion: The data significantly deviates from a normal distribution (p < {alpha}).\")\n",
        "        print(\"A non-parametric test may be more appropriate.\")\n",
        "    else:\n",
        "        print(f\"Conclusion: No significant evidence against normality (p > {alpha}).\")\n",
        "        print(\"A parametric test is likely appropriate.\")\n",
        "\n",
        "    return shapiro_p > alpha  # Returns True if data appears normal\n",
        "\n",
        "# Test normality for each group in our heart disease dataset\n",
        "print(\"\\nChecking normality for key variables by heart disease status:\")\n",
        "\n",
        "# Age by heart disease status\n",
        "print(\"\\n=== Age ===\")\n",
        "disease_group_age = heart_data[heart_data['target'] == 1]['age']\n",
        "no_disease_group_age = heart_data[heart_data['target'] == 0]['age']\n",
        "check_normality(disease_group_age, \"Age (Disease Group)\")\n",
        "check_normality(no_disease_group_age, \"Age (No Disease Group)\")\n",
        "\n",
        "# Cholesterol by heart disease status\n",
        "print(\"\\n=== Cholesterol ===\")\n",
        "disease_group_chol = heart_data[heart_data['target'] == 1]['chol']\n",
        "no_disease_group_chol = heart_data[heart_data['target'] == 0]['chol']\n",
        "check_normality(disease_group_chol, \"Cholesterol (Disease Group)\")\n",
        "check_normality(no_disease_group_chol, \"Cholesterol (No Disease Group)\")\n",
        "\n",
        "# Maximum heart rate by heart disease status\n",
        "print(\"\\n=== Maximum Heart Rate ===\")\n",
        "disease_group_thalach = heart_data[heart_data['target'] == 1]['thalach']\n",
        "no_disease_group_thalach = heart_data[heart_data['target'] == 0]['thalach']\n",
        "check_normality(disease_group_thalach, \"Max Heart Rate (Disease Group)\")\n",
        "check_normality(no_disease_group_thalach, \"Max Heart Rate (No Disease Group)\")"
      ],
      "metadata": {
        "id": "4f8SOgyv4KkN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# 2. Mann-Whitney U Test\n",
        "\n",
        "The Mann-Whitney U test is a non-parametric alternative to the independent samples t-test. It's used to determine whether two independent samples come from the same distribution.\n",
        "\n",
        "Unlike the t-test which compares means, the Mann-Whitney U test compares the entire distributions by ranking all observations and analyzing the ranks.\n",
        "\n",
        "## Key Characteristics:\n",
        "\n",
        "1. **Assumptions:**\n",
        "   - Samples are independent\n",
        "   - The dependent variable is at least ordinal (can be ranked)\n",
        "   - The distributions of both populations are similar in shape (for median inference)\n",
        "\n",
        "2. **Null Hypothesis (H₀):**\n",
        "   - The distributions of both populations are identical\n",
        "   - Alternative interpretation if distributions are similar in shape: The medians of both populations are equal\n",
        "\n",
        "3. **Alternative Hypothesis (H₁):**\n",
        "   - The distributions of the two populations differ in some way\n",
        "   - Alternative interpretation if distributions are similar in shape: The medians of the populations differ\n",
        "\n",
        "4. **Test Procedure:**\n",
        "   - Combine all observations from both samples and rank them\n",
        "   - Calculate the sum of ranks for each sample\n",
        "   - Calculate the U statistic based on these rank sums\n",
        "   - Determine significance based on the U distribution\n",
        "\n",
        "5. **When to Use:**\n",
        "   - When data is ordinal or continuous but not normally distributed\n",
        "   - When outliers are present\n",
        "   - When sample sizes are small\n",
        "   - When comparing distributions, not just central tendency\n",
        "\n",
        "Next, we'll implement the Mann-Whitney U test for our heart disease dataset.\n"
      ],
      "metadata": {
        "id": "JSYuJSiE6fsh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5n9SmIYcrCk4"
      },
      "outputs": [],
      "source": [
        "\n",
        "def perform_mannwhitney_test(data, group_var, test_var, display_name=None):\n",
        "\n",
        "    if display_name is None:\n",
        "        display_name = test_var\n",
        "\n",
        "    # Ensure the data has only two groups e.g., non heart disease and with heart disease\n",
        "    group_values = data[group_var].unique()\n",
        "    if len(group_values) != 2:\n",
        "        print(f\"Error: {group_var} must have exactly 2 unique values for Mann-Whitney test.\")\n",
        "        return\n",
        "\n",
        "    group1 = data[data[group_var] == group_values[0]][test_var].dropna()  #In our case these would be no heart disease - 164 data points\n",
        "    group2 = data[data[group_var] == group_values[1]][test_var].dropna()  # with heart disease - 139 data points\n",
        "\n",
        "    # Calculate descriptive statistics for each group\n",
        "    n1, n2 = len(group1), len(group2)\n",
        "    mean1, mean2 = group1.mean(), group2.mean()\n",
        "    median1, median2 = group1.median(), group2.median()\n",
        "    std1, std2 = group1.std(), group2.std()\n",
        "    iqr1 = group1.quantile(0.75) - group1.quantile(0.25)\n",
        "    iqr2 = group2.quantile(0.75) - group2.quantile(0.25)\n",
        "\n",
        "    print(f\"\\nMann-Whitney U Test: Comparing {display_name} between {group_values[0]} and {group_values[1]} groups\")\n",
        "    print(f\"\\nDescriptive Statistics:\")\n",
        "    print(f\"  {group_values[0]}: n = {n1}, Mean = {mean1:.2f}, Median = {median1:.2f}, SD = {std1:.2f}, IQR = {iqr1:.2f}\")\n",
        "    print(f\"  {group_values[1]}: n = {n2}, Mean = {mean2:.2f}, Median = {median2:.2f}, SD = {std2:.2f}, IQR = {iqr2:.2f}\")\n",
        "\n",
        "    # Perform Mann-Whitney U test\n",
        "    # Note: 'alternative' parameter set to 'two-sided' for a two-tailed test\n",
        "    u_stat, p_value = mannwhitneyu(group1, group2, alternative='two-sided')\n",
        "\n",
        "    # Calculate effect size (r = Z / sqrt(N))\n",
        "    # Convert U to Z score for the effect size calculation\n",
        "    n_total = n1 + n2\n",
        "    mean_u = (n1 * n2) / 2\n",
        "    std_u = np.sqrt((n1 * n2 * (n1 + n2 + 1)) / 12)\n",
        "    z_score = (u_stat - mean_u) / std_u\n",
        "    effect_size_r = abs(z_score) / np.sqrt(n_total)\n",
        "\n",
        "    # Interpret effect size\n",
        "    if effect_size_r < 0.1:\n",
        "        effect_interpretation = \"negligible\"\n",
        "    elif effect_size_r < 0.3:\n",
        "        effect_interpretation = \"small\"\n",
        "    elif effect_size_r < 0.5:\n",
        "        effect_interpretation = \"medium\"\n",
        "    else:\n",
        "        effect_interpretation = \"large\"\n",
        "\n",
        "    # Print Mann-Whitney U test results\n",
        "    print(\"\\nMann-Whitney U Test Results:\")\n",
        "    print(f\"  U statistic = {u_stat:.2f}\")\n",
        "    print(f\"  p-value = {p_value:.6f}\")\n",
        "    print(f\"  Effect size r = {effect_size_r:.4f} ({effect_interpretation} effect)\")\n",
        "\n",
        "    # Print interpretation\n",
        "    if p_value < 0.05:\n",
        "        print(f\"  Result: Statistically significant difference in {display_name} between groups\")\n",
        "        print(f\"  The distributions of {display_name} for {group_values[0]} and {group_values[1]} are significantly different\")\n",
        "    else:\n",
        "        print(f\"  Result: No statistically significant difference in {display_name} between groups\")\n",
        "        print(f\"  No evidence that the distributions of {display_name} differ between {group_values[0]} and {group_values[1]}\")\n",
        "\n",
        "    # Create visualizations\n",
        "    plt.figure(figsize=(15, 10))\n",
        "\n",
        "    # 1. Box plots\n",
        "    plt.subplot(2, 2, 1)\n",
        "    sns.boxplot(x=group_var, y=test_var, data=data)\n",
        "    plt.title(f'Box Plot of {display_name} by {group_var}')\n",
        "    plt.ylabel(display_name)\n",
        "\n",
        "    # 2. Violin plots\n",
        "    plt.subplot(2, 2, 2)\n",
        "    sns.violinplot(x=group_var, y=test_var, data=data, inner='quartile')\n",
        "    plt.title(f'Violin Plot of {display_name} by {group_var}')\n",
        "    plt.ylabel(display_name)\n",
        "\n",
        "    # 3. Overlapping histograms\n",
        "    plt.subplot(2, 2, 3)\n",
        "    sns.histplot(group1, color='blue', alpha=0.5, label=group_values[0], kde=True)\n",
        "    sns.histplot(group2, color='orange', alpha=0.5, label=group_values[1], kde=True)\n",
        "    plt.title(f'Distribution of {display_name} by {group_var}')\n",
        "    plt.xlabel(display_name)\n",
        "    plt.legend()\n",
        "\n",
        "    # 4. Emperical Cumulative distribution function (ECDF) plot - useful for Mann-Whitney U test\n",
        "    plt.subplot(2, 2, 4)\n",
        "\n",
        "    # Calculate ECDF for each group\n",
        "    def ecdf(x):\n",
        "        # Count the proportion of values less than or equal to each value\n",
        "        x = np.sort(x)\n",
        "        y = np.arange(1, len(x) + 1) / len(x)\n",
        "        return x, y\n",
        "\n",
        "    x1, y1 = ecdf(group1)\n",
        "    x2, y2 = ecdf(group2)\n",
        "\n",
        "    plt.step(x1, y1, label=group_values[0], where='post')\n",
        "    plt.step(x2, y2, label=group_values[1], where='post')\n",
        "\n",
        "    plt.title(f'Empirical Cumulative Distribution of {display_name}')\n",
        "    plt.xlabel(display_name)\n",
        "    plt.ylabel('Cumulative Probability')\n",
        "    plt.legend()\n",
        "\n",
        "    # Add p-value annotation to the plot\n",
        "    sig_text = f\"Mann-Whitney U Test\\np = {p_value:.4f}\"\n",
        "    if p_value < 0.05:\n",
        "        sig_text += \"\\n(Significant)\"\n",
        "    else:\n",
        "        sig_text += \"\\n(Not Significant)\"\n",
        "\n",
        "    plt.figtext(0.5, 0.01, sig_text, ha='center', fontsize=12,\n",
        "                bbox={'facecolor':'white', 'alpha':0.8, 'pad':5})\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.subplots_adjust(bottom=0.15)\n",
        "    plt.suptitle(f'Mann-Whitney U Test: {display_name} by {group_var}', fontsize=16, y=1.05)\n",
        "    plt.show()\n",
        "\n",
        "    # Return results for further analysis if needed\n",
        "    return {\n",
        "        'u_statistic': u_stat,\n",
        "        'p_value': p_value,\n",
        "        'effect_size_r': effect_size_r,\n",
        "        'n1': n1,\n",
        "        'n2': n2\n",
        "    }\n",
        "\n",
        "# Apply the Mann-Whitney U test to our heart disease dataset variables\n",
        "print(\"\\n\\nApplying Mann-Whitney U Test to our dataset variables:\")\n",
        "\n",
        "# Analyze age differences between heart disease and no heart disease groups\n",
        "print(\"\\n=== Mann-Whitney U Test for Age ===\")\n",
        "age_mw_results = perform_mannwhitney_test(heart_data, 'target', 'age', 'Age (years)')\n",
        "\n",
        "# Analyze cholesterol differences between heart disease and no heart disease groups\n",
        "print(\"\\n=== Mann-Whitney U Test for Cholesterol ===\")\n",
        "chol_mw_results = perform_mannwhitney_test(heart_data, 'target', 'chol', 'Cholesterol (mg/dl)')\n",
        "\n",
        "# Analyze maximum heart rate differences between heart disease and no heart disease groups\n",
        "print(\"\\n=== Mann-Whitney U Test for Maximum Heart Rate ===\")\n",
        "hr_mw_results = perform_mannwhitney_test(heart_data, 'target', 'thalach', 'Maximum Heart Rate')\n",
        "\n",
        "# Compare resting blood pressure differences\n",
        "print(\"\\n=== Mann-Whitney U Test for Resting Blood Pressure ===\")\n",
        "bp_mw_results = perform_mannwhitney_test(heart_data, 'target', 'trestbps', 'Resting Blood Pressure (mm Hg)')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# 3. Wilcoxon Signed-Rank Test\n",
        "\n",
        "The Wilcoxon signed-rank test is a non-parametric alternative to the paired samples t-test. It's used to compare two related samples to assess whether their population mean ranks differ.\n",
        "\n",
        "## Key Characteristics:\n",
        "\n",
        "1. **Assumptions:**\n",
        "   - The data are paired and come from the same population\n",
        "   - Each pair is chosen randomly and independently\n",
        "   - The dependent variable is measured on at least an ordinal scale\n",
        "   - The distribution of the differences is symmetric (but doesn't need to be normal)\n",
        "\n",
        "2. **Null Hypothesis (H₀):**\n",
        "   - The median difference between pairs of observations is zero\n",
        "\n",
        "3. **Alternative Hypothesis (H₁):**\n",
        "   - The median difference between pairs of observations is not zero\n",
        "\n",
        "4. **Test Procedure:**\n",
        "   - Calculate the differences between paired observations\n",
        "   - Rank the absolute differences\n",
        "   - Assign the sign (+ or -) back to each rank\n",
        "   - Calculate the sum of positive ranks (W+) and negative ranks (W-)\n",
        "   - Test statistic is the smaller of |W+| and |W-|\n",
        "\n",
        "5. **When to Use:**\n",
        "   - When data is ordinal or continuous but not normally distributed\n",
        "   - When differences between pairs are not normally distributed\n",
        "   - When outliers are present\n",
        "\n",
        "Since our heart disease dataset doesn't include paired measurements (e.g., before and after treatment), we'll simulate data for demonstration purposes, similar to what was done in Tutorial 4.\n"
      ],
      "metadata": {
        "id": "BGUTqDSn6_ma"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def perform_wilcoxon_test(before_data, after_data, var_name, display_name=None):\n",
        "\n",
        "    if display_name is None:\n",
        "        display_name = var_name\n",
        "\n",
        "    # Make sure data is of equal length\n",
        "    if len(before_data) != len(after_data):\n",
        "        print(\"Error: Before and after data must have the same length\")\n",
        "        return\n",
        "\n",
        "    # Calculate differences\n",
        "    diff = after_data - before_data\n",
        "\n",
        "    # Check whether differences are symmetric around the median\n",
        "    # This is an assumption of the Wilcoxon signed-rank test\n",
        "    print(f\"\\nChecking symmetry assumption for the differences in {var_name}:\")\n",
        "\n",
        "    # Calculate the median of the differences\n",
        "    median_diff = np.median(diff)\n",
        "\n",
        "    # Calculate distances from the median\n",
        "    distances = np.abs(diff - median_diff)\n",
        "\n",
        "    # Split the data into values above and below the median\n",
        "    above_median = distances[diff > median_diff]\n",
        "    below_median = distances[diff < median_diff]\n",
        "\n",
        "    # Use Kolmogorov-Smirnov test to check if distributions are similar\n",
        "    if len(above_median) > 0 and len(below_median) > 0:  # Check to avoid empty arrays\n",
        "        _, p_ks = stats.ks_2samp(above_median, below_median)\n",
        "        print(f\"  Kolmogorov-Smirnov test p-value for symmetry: {p_ks:.4f}\")\n",
        "\n",
        "        if p_ks < 0.05:\n",
        "            print(\"  Warning: The distribution of differences may not be symmetric.\")\n",
        "            print(\"  Consider using the Sign Test instead of Wilcoxon signed-rank test.\")\n",
        "        else:\n",
        "            print(\"  The distribution of differences appears to be symmetric.\")\n",
        "    else:\n",
        "        print(\"  Cannot test symmetry: too many identical values.\")\n",
        "\n",
        "    # Perform the Wilcoxon signed-rank test\n",
        "    try:\n",
        "        # Only include non-zero differences in the test\n",
        "        # (Wilcoxon test discards pairs with no differences)\n",
        "        non_zero_diff = diff[diff != 0]\n",
        "        if len(non_zero_diff) < 6:  # Generally need at least 6 pairs with non-zero differences\n",
        "            print(f\"  Warning: Only {len(non_zero_diff)} non-zero differences found.\")\n",
        "            print(\"  Wilcoxon test may have low power. Consider collecting more data.\")\n",
        "\n",
        "        stat, p_value = wilcoxon(before_data, after_data, alternative='two-sided')\n",
        "\n",
        "        # Calculate descriptive statistics\n",
        "        mean_before, std_before = np.mean(before_data), np.std(before_data, ddof=1)\n",
        "        mean_after, std_after = np.mean(after_data), np.std(after_data, ddof=1)\n",
        "        mean_diff = mean_after - mean_before\n",
        "        median_before, median_after = np.median(before_data), np.median(after_data)\n",
        "        median_diff = median_after - median_before\n",
        "        n = len(before_data)\n",
        "        n_nonzero = len(non_zero_diff)\n",
        "\n",
        "        # Calculate effect size (r = Z / sqrt(N))\n",
        "        # Convert Wilcoxon statistic to Z-score\n",
        "        z = (stat - (n_nonzero * (n_nonzero + 1)) / 4) / np.sqrt((n_nonzero * (n_nonzero + 1) * (2 * n_nonzero + 1)) / 24)\n",
        "        effect_size_r = abs(z) / np.sqrt(n)\n",
        "\n",
        "        # Interpret effect size\n",
        "        if effect_size_r < 0.1:\n",
        "            effect_interpretation = \"negligible\"\n",
        "        elif effect_size_r < 0.3:\n",
        "            effect_interpretation = \"small\"\n",
        "        elif effect_size_r < 0.5:\n",
        "            effect_interpretation = \"medium\"\n",
        "        else:\n",
        "            effect_interpretation = \"large\"\n",
        "\n",
        "        # Calculate 95% confidence interval for the median difference\n",
        "        # This is a more robust approach than using mean differences\n",
        "        alpha = 0.05\n",
        "        sorted_diff = np.sort(diff)\n",
        "\n",
        "        # Calculate ranks for confidence interval\n",
        "        # Based on the binomial distribution for the sign test\n",
        "        lower_rank = int(np.ceil((n - 1.96 * np.sqrt(n)) / 2))\n",
        "        upper_rank = int(np.ceil((n + 1.96 * np.sqrt(n)) / 2))\n",
        "\n",
        "        # Ensure ranks are within bounds\n",
        "        lower_rank = max(0, lower_rank)\n",
        "        upper_rank = min(n - 1, upper_rank)\n",
        "\n",
        "        # Get confidence interval values\n",
        "        if n > 0:\n",
        "            ci_lower = sorted_diff[lower_rank]\n",
        "            ci_upper = sorted_diff[upper_rank]\n",
        "        else:\n",
        "            ci_lower, ci_upper = np.nan, np.nan\n",
        "\n",
        "        # Print results\n",
        "        print(\"\\nWilcoxon Signed-Rank Test Results:\")\n",
        "        print(f\"  Comparing {display_name} before and after\")\n",
        "        print(f\"  Before: Mean = {mean_before:.2f}, Median = {median_before:.2f}, SD = {std_before:.2f}\")\n",
        "        print(f\"  After: Mean = {mean_after:.2f}, Median = {median_after:.2f}, SD = {std_after:.2f}\")\n",
        "        print(f\"  Mean difference (After - Before): {mean_diff:.2f}\")\n",
        "        print(f\"  Median difference (After - Before): {median_diff:.2f}, 95% CI [{ci_lower:.2f}, {ci_upper:.2f}]\")\n",
        "        print(f\"  Wilcoxon statistic = {stat:.2f}, p-value = {p_value:.4f}\")\n",
        "        print(f\"  Effect size r = {effect_size_r:.4f} ({effect_interpretation} effect)\")\n",
        "\n",
        "        if p_value < 0.05:\n",
        "            print(f\"  Result: Statistically significant change in {display_name}\")\n",
        "        else:\n",
        "            print(f\"  Result: No statistically significant change in {display_name}\")\n",
        "\n",
        "        # Create visualizations\n",
        "        plt.figure(figsize=(15, 10))\n",
        "\n",
        "        # 1. Box plots\n",
        "        plt.subplot(2, 2, 1)\n",
        "        box_data = pd.DataFrame({\n",
        "            'Before': before_data,\n",
        "            'After': after_data\n",
        "        })\n",
        "        sns.boxplot(data=box_data)\n",
        "        plt.title(f'Box Plot of {display_name} Before and After')\n",
        "        plt.ylabel(display_name)\n",
        "\n",
        "        # 2. Paired line plot\n",
        "        plt.subplot(2, 2, 2)\n",
        "        for i in range(n):\n",
        "            plt.plot([1, 2], [before_data[i], after_data[i]], 'k-', alpha=0.3)\n",
        "\n",
        "        # Add mean points\n",
        "        plt.plot(1, mean_before, 'ro', markersize=10, label='Mean Before')\n",
        "        plt.plot(2, mean_after, 'bo', markersize=10, label='Mean After')\n",
        "\n",
        "        # Connect means\n",
        "        plt.plot([1, 2], [mean_before, mean_after], 'r--', linewidth=2)\n",
        "\n",
        "        # Add median points\n",
        "        plt.plot(1, median_before, 'rx', markersize=10, label='Median Before')\n",
        "        plt.plot(2, median_after, 'bx', markersize=10, label='Median After')\n",
        "\n",
        "        # Connect medians (important for Wilcoxon test)\n",
        "        plt.plot([1, 2], [median_before, median_after], 'b--', linewidth=2)\n",
        "\n",
        "        plt.xticks([1, 2], ['Before', 'After'])\n",
        "        plt.title(f'Paired Changes in {display_name}')\n",
        "        plt.ylabel(display_name)\n",
        "        plt.legend()\n",
        "\n",
        "        # 3. Histogram of differences\n",
        "        plt.subplot(2, 2, 3)\n",
        "        sns.histplot(diff, kde=True)\n",
        "        plt.axvline(0, color='r', linestyle='--')\n",
        "        plt.axvline(median_diff, color='b', linestyle='-', label=f'Median Diff: {median_diff:.2f}')\n",
        "        plt.title(f'Distribution of Differences in {display_name} (After - Before)')\n",
        "        plt.xlabel('Difference')\n",
        "        plt.legend()\n",
        "\n",
        "        # 4. Scatter plot of before vs after values\n",
        "        plt.subplot(2, 2, 4)\n",
        "        plt.scatter(before_data, after_data, alpha=0.6)\n",
        "\n",
        "        # Add diagonal line (no change line)\n",
        "        min_val = min(np.min(before_data), np.min(after_data))\n",
        "        max_val = max(np.max(before_data), np.max(after_data))\n",
        "        plt.plot([min_val, max_val], [min_val, max_val], 'r--', label='No Change Line')\n",
        "\n",
        "        # Add regression line\n",
        "        slope, intercept = np.polyfit(before_data, after_data, 1)\n",
        "        plt.plot([min_val, max_val], [slope*min_val + intercept, slope*max_val + intercept], 'g-', label='Regression Line')\n",
        "\n",
        "        plt.xlabel('Before')\n",
        "        plt.ylabel('After')\n",
        "        plt.title(f'Before vs. After {display_name} Values')\n",
        "        plt.legend()\n",
        "\n",
        "        # Add p-value annotation to the plot\n",
        "        sig_text = f\"Wilcoxon Signed-Rank Test\\np = {p_value:.4f}\"\n",
        "        if p_value < 0.05:\n",
        "            sig_text += \"\\n(Significant)\"\n",
        "        else:\n",
        "            sig_text += \"\\n(Not Significant)\"\n",
        "\n",
        "        plt.figtext(0.5, 0.01, sig_text, ha='center', fontsize=12,\n",
        "                    bbox={'facecolor':'white', 'alpha':0.8, 'pad':5})\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.subplots_adjust(bottom=0.15)\n",
        "        plt.suptitle(f'Wilcoxon Signed-Rank Test: {display_name}', fontsize=16, y=1.05)\n",
        "        plt.show()\n",
        "\n",
        "        # Return the results for further analysis if needed\n",
        "        return {\n",
        "            'wilcoxon_statistic': stat,\n",
        "            'p_value': p_value,\n",
        "            'effect_size_r': effect_size_r,\n",
        "            'mean_difference': mean_diff,\n",
        "            'median_difference': median_diff,\n",
        "            'ci_lower': ci_lower,\n",
        "            'ci_upper': ci_upper,\n",
        "            'n': n\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\"Error performing Wilcoxon test: {e}\")\n",
        "        print(\"This can happen if all differences are zero or if there are too few samples.\")\n",
        "        return None\n",
        "\n",
        "# Since we don't have paired data in our heart disease dataset, we'll simulate blood pressure data\n",
        "# for demonstration purposes, just like in Tutorial 4\n",
        "print(\"\\n\\nWilcoxon Signed-Rank Test with Simulated Blood Pressure Data:\")\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Two scenarios for demonstration: moderate effect and small effect\n",
        "print(\"\\n=== Scenario 1: Moderate Treatment Effect ===\")\n",
        "num_patients = 100\n",
        "# Simulate before data with mean 140 and SD 15\n",
        "bp_before1 = np.random.normal(140, 15, num_patients)\n",
        "\n",
        "# Simulate a moderate treatment effect: decrease of ~5 mmHg on average\n",
        "true_effect1 = -5  # desired average decrease\n",
        "noise_sd1 = 8      # realistic post-treatment variation\n",
        "correlation1 = 0.7  # strong correlation for paired data\n",
        "\n",
        "# Add noise correlated with the before values\n",
        "random_noise1 = np.random.normal(0, noise_sd1, num_patients)\n",
        "bp_after1 = bp_before1 + true_effect1 + (1 - correlation1) * random_noise1\n",
        "\n",
        "# Run the Wilcoxon signed-rank test on the simulated blood pressure data with moderate effect\n",
        "bp_wilcoxon_results1 = perform_wilcoxon_test(bp_before1, bp_after1, 'blood_pressure', 'Blood Pressure (mmHg) - Moderate Effect')\n",
        "\n",
        "print(\"\\n=== Scenario 2: Small Treatment Effect ===\")\n",
        "# Simulate a small treatment effect: decrease of ~2 mmHg on average\n",
        "true_effect2 = -2  # smaller average decrease\n",
        "noise_sd2 = 10     # more post-treatment variation\n",
        "correlation2 = 0.6  # moderate correlation for paired data\n",
        "\n",
        "# Add noise correlated with the before values\n",
        "bp_before2 = np.random.normal(140, 15, num_patients)  # same baseline\n",
        "random_noise2 = np.random.normal(0, noise_sd2, num_patients)\n",
        "bp_after2 = bp_before2 + true_effect2 + (1 - correlation2) * random_noise2\n",
        "\n",
        "# Run the Wilcoxon signed-rank test on the simulated blood pressure data with small effect\n",
        "bp_wilcoxon_results2 = perform_wilcoxon_test(bp_before2, bp_after2, 'blood_pressure', 'Blood Pressure (mmHg) - Small Effect')"
      ],
      "metadata": {
        "id": "pXZQ12hH7Lca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Sign Test\n",
        "\n",
        "The sign test is an even simpler non-parametric alternative to the paired t-test. It only considers the direction (sign) of the differences between pairs, ignoring the magnitude of these differences.\n",
        "\n",
        "## Key Characteristics:\n",
        "\n",
        "1. **Assumptions:**\n",
        "   - The data are paired and come from the same population\n",
        "   - Each pair is chosen randomly and independently\n",
        "   - The data are at least ordinal (can be ranked)\n",
        "   - No assumption about the shape of the distribution of differences\n",
        "\n",
        "2. **Null Hypothesis (H₀):**\n",
        "   - The median difference is zero\n",
        "   - The probability of a positive difference equals the probability of a negative difference\n",
        "\n",
        "3. **Alternative Hypothesis (H₁):**\n",
        "   - The median difference is not zero\n",
        "   - The probability of a positive difference does not equal the probability of a negative difference\n",
        "\n",
        "4. **Test Procedure:**\n",
        "   - Calculate the differences between paired observations\n",
        "   - Count the number of positive and negative differences (ignoring zeros)\n",
        "   - Use the binomial distribution to determine significance\n",
        "\n",
        "5. **When to Use:**\n",
        "   - When the assumption of symmetry for the Wilcoxon test is violated\n",
        "   - When only the direction of change matters, not the magnitude\n",
        "   - When data contains extreme outliers\n",
        "   - When dealing with ordinal data where exact differences are not meaningful\n",
        "\n",
        "The sign test is less powerful than the Wilcoxon signed-rank test when the Wilcoxon test's assumptions are met, but it's more robust to violations of those assumptions.\n"
      ],
      "metadata": {
        "id": "59IArAwg7ecE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def perform_sign_test(before_data, after_data, var_name, display_name=None):\n",
        "\n",
        "    if display_name is None:\n",
        "        display_name = var_name\n",
        "\n",
        "    # Make sure data is of equal length\n",
        "    if len(before_data) != len(after_data):\n",
        "        print(\"Error: Before and after data must have the same length\")\n",
        "        return\n",
        "\n",
        "    # Calculate differences\n",
        "    diff = after_data - before_data\n",
        "\n",
        "    # Get signs of differences (positive, negative, zero)\n",
        "    pos_count = np.sum(diff > 0)\n",
        "    neg_count = np.sum(diff < 0)\n",
        "    zero_count = np.sum(diff == 0)\n",
        "\n",
        "    # Total non-zero differences\n",
        "    n_nonzero = pos_count + neg_count\n",
        "\n",
        "    print(f\"\\nSign Test Results for {display_name}:\")\n",
        "    print(f\"  Number of positive differences: {pos_count}\")\n",
        "    print(f\"  Number of negative differences: {neg_count}\")\n",
        "    print(f\"  Number of zero differences: {zero_count}\")\n",
        "\n",
        "    if n_nonzero < 10:\n",
        "        print(\"  Warning: Small sample size. The sign test has low power with fewer than 10 non-zero differences.\")\n",
        "\n",
        "    # Calculate descriptive statistics\n",
        "    mean_before = np.mean(before_data)\n",
        "    mean_after = np.mean(after_data)\n",
        "    mean_diff = mean_after - mean_before\n",
        "\n",
        "    median_before = np.median(before_data)\n",
        "    median_after = np.median(after_data)\n",
        "    median_diff = median_after - median_before\n",
        "\n",
        "    # Perform the sign test using binomial test\n",
        "    # Under the null hypothesis, we expect equal numbers of positive and negative differences\n",
        "    # So we test whether the proportion of positive differences differs from 0.5\n",
        "    if n_nonzero > 0:\n",
        "        # Use binomtest from scipy.stats for the sign test\n",
        "        # We test whether the number of positive differences out of all non-zero differences\n",
        "        # is significantly different from the expected 50% under the null hypothesis\n",
        "        result = binomtest(pos_count, n_nonzero, p=0.5)\n",
        "        p_value = result.pvalue\n",
        "\n",
        "        # Calculate effect size (Cohen's g)\n",
        "        # g = |proportion - 0.5| / 0.5\n",
        "        proportion = pos_count / n_nonzero\n",
        "        effect_size_g = abs(proportion - 0.5) / 0.5\n",
        "\n",
        "        # Interpret effect size\n",
        "        if effect_size_g < 0.05:\n",
        "            effect_interpretation = \"negligible\"\n",
        "        elif effect_size_g < 0.15:\n",
        "            effect_interpretation = \"small\"\n",
        "        elif effect_size_g < 0.25:\n",
        "            effect_interpretation = \"medium\"\n",
        "        else:\n",
        "            effect_interpretation = \"large\"\n",
        "\n",
        "        # Print sign test results\n",
        "        print(\"\\nSign Test Statistics:\")\n",
        "        print(f\"  Before: Mean = {mean_before:.2f}, Median = {median_before:.2f}\")\n",
        "        print(f\"  After: Mean = {mean_after:.2f}, Median = {median_after:.2f}\")\n",
        "        print(f\"  Mean difference (After - Before): {mean_diff:.2f}\")\n",
        "        print(f\"  Median difference (After - Before): {median_diff:.2f}\")\n",
        "        print(f\"  Proportion of positive differences: {proportion:.4f}\")\n",
        "        print(f\"  p-value: {p_value:.4f}\")\n",
        "        print(f\"  Effect size (Cohen's g): {effect_size_g:.4f} ({effect_interpretation} effect)\")\n",
        "\n",
        "        if p_value < 0.05:\n",
        "            if proportion > 0.5:\n",
        "                print(f\"  Result: Statistically significant increase in {display_name}\")\n",
        "            else:\n",
        "                print(f\"  Result: Statistically significant decrease in {display_name}\")\n",
        "        else:\n",
        "            print(f\"  Result: No statistically significant change in {display_name}\")\n",
        "\n",
        "        # Create visualizations\n",
        "        plt.figure(figsize=(12, 10))\n",
        "\n",
        "        # 1. Bar chart of positive/negative/zero differences\n",
        "        plt.subplot(2, 2, 1)\n",
        "        counts = [pos_count, neg_count, zero_count]\n",
        "        categories = ['Positive', 'Negative', 'No Change']\n",
        "        colors = ['green', 'red', 'gray']\n",
        "        plt.bar(categories, counts, color=colors)\n",
        "        plt.title('Distribution of Difference Signs')\n",
        "        plt.ylabel('Count')\n",
        "\n",
        "        # Add count labels on bars\n",
        "        for i, count in enumerate(counts):\n",
        "            plt.text(i, count + 0.5, str(count), ha='center')\n",
        "\n",
        "        # Add horizontal line at expected count under null hypothesis\n",
        "        expected = n_nonzero / 2\n",
        "        plt.axhline(y=expected, color='blue', linestyle='--',\n",
        "                   label=f'Expected under H₀: {expected:.1f}')\n",
        "        plt.legend()\n",
        "\n",
        "        # 2. Scatter plot with +/- indicators\n",
        "        plt.subplot(2, 2, 2)\n",
        "        plt.scatter(before_data, after_data, alpha=0.5)\n",
        "\n",
        "        # Color points based on the sign of the difference\n",
        "        plt.scatter(before_data[diff > 0], after_data[diff > 0], color='green', alpha=0.7,\n",
        "                   label='Increase')\n",
        "        plt.scatter(before_data[diff < 0], after_data[diff < 0], color='red', alpha=0.7,\n",
        "                   label='Decrease')\n",
        "        plt.scatter(before_data[diff == 0], after_data[diff == 0], color='gray', alpha=0.7,\n",
        "                   label='No Change')\n",
        "\n",
        "        # Add diagonal line (no change line)\n",
        "        min_val = min(np.min(before_data), np.min(after_data))\n",
        "        max_val = max(np.max(before_data), np.max(after_data))\n",
        "        plt.plot([min_val, max_val], [min_val, max_val], 'k--')\n",
        "\n",
        "        plt.xlabel('Before')\n",
        "        plt.ylabel('After')\n",
        "        plt.title(f'Before vs. After {display_name} Values')\n",
        "        plt.legend()\n",
        "\n",
        "        # 3. Box plot of before and after values\n",
        "        plt.subplot(2, 2, 3)\n",
        "        box_data = pd.DataFrame({\n",
        "            'Before': before_data,\n",
        "            'After': after_data\n",
        "        })\n",
        "        sns.boxplot(data=box_data)\n",
        "        plt.title(f'Box Plot of {display_name} Before and After')\n",
        "        plt.ylabel(display_name)\n",
        "\n",
        "        # Add median lines\n",
        "        plt.axhline(y=median_before, color='blue', linestyle='--', label=f'Median Before: {median_before:.1f}')\n",
        "        plt.axhline(y=median_after, color='red', linestyle='--', label=f'Median After: {median_after:.1f}')\n",
        "        plt.legend()\n",
        "\n",
        "        # 4. Histogram of differences\n",
        "        plt.subplot(2, 2, 4)\n",
        "        sns.histplot(diff, kde=True)\n",
        "        plt.axvline(0, color='k', linestyle='--', label='Zero Difference')\n",
        "        plt.axvline(median_diff, color='r', linestyle='-', label=f'Median Diff: {median_diff:.2f}')\n",
        "        plt.title(f'Distribution of Differences in {display_name}')\n",
        "        plt.xlabel('Difference (After - Before)')\n",
        "        plt.legend()\n",
        "\n",
        "        # Add p-value annotation to the plot\n",
        "        sig_text = f\"Sign Test\\np = {p_value:.4f}\"\n",
        "        if p_value < 0.05:\n",
        "            sig_text += \"\\n(Significant)\"\n",
        "        else:\n",
        "            sig_text += \"\\n(Not Significant)\"\n",
        "\n",
        "        plt.figtext(0.5, 0.01, sig_text, ha='center', fontsize=12,\n",
        "                    bbox={'facecolor':'white', 'alpha':0.8, 'pad':5})\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.subplots_adjust(bottom=0.15)\n",
        "        plt.suptitle(f'Sign Test: {display_name}', fontsize=16, y=1.05)\n",
        "        plt.show()\n",
        "\n",
        "        # Return the results for further analysis if needed\n",
        "        return {\n",
        "            'positive_count': pos_count,\n",
        "            'negative_count': neg_count,\n",
        "            'zero_count': zero_count,\n",
        "            'p_value': p_value,\n",
        "            'effect_size_g': effect_size_g,\n",
        "            'n_nonzero': n_nonzero,\n",
        "            'proportion': proportion\n",
        "        }\n",
        "    else:\n",
        "        print(\"  Result: Cannot perform sign test - all differences are zero.\")\n",
        "        return None\n",
        "\n",
        "# Apply the sign test to the same simulated blood pressure data\n",
        "print(\"\\n\\nSign Test with Simulated Blood Pressure Data:\")\n",
        "\n",
        "# Scenario 1: Moderate effect\n",
        "print(\"\\n=== Scenario 1: Moderate Treatment Effect ===\")\n",
        "bp_sign_results1 = perform_sign_test(bp_before1, bp_after1, 'blood_pressure', 'Blood Pressure (mmHg) - Moderate Effect')\n",
        "\n",
        "# Scenario 2: Small effect\n",
        "print(\"\\n=== Scenario 2: Small Treatment Effect ===\")\n",
        "bp_sign_results2 = perform_sign_test(bp_before2, bp_after2, 'blood_pressure', 'Blood Pressure (mmHg) - Small Effect')"
      ],
      "metadata": {
        "id": "n-g-3VE3t3oD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# 5. Comparing Parametric and Non-parametric Results\n",
        "\n",
        "Now let's compare the results from the parametric tests (Tutorial 4) with their non-parametric alternatives (this tutorial) to see how they differ and when to use each.\n",
        "\n",
        "## Independent t-test vs. Mann-Whitney U test:\n",
        "\n",
        "We'll compare the results of the independent t-test and Mann-Whitney U test for the same variables.\n"
      ],
      "metadata": {
        "id": "-S_5-iV78GtL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def compare_parametric_nonparametric(var_name, display_name=None):\n",
        "\n",
        "    if display_name is None:\n",
        "        display_name = var_name\n",
        "\n",
        "    print(f\"\\nComparing Parametric and Non-parametric Tests for {display_name}:\")\n",
        "\n",
        "    # Split the data by heart disease status\n",
        "    group1 = heart_data[heart_data['target'] == 1][var_name].dropna()\n",
        "    group2 = heart_data[heart_data['target'] == 0][var_name].dropna()\n",
        "\n",
        "    # Check normality assumption\n",
        "    print(\"\\nNormality Check:\")\n",
        "    shapiro1 = stats.shapiro(group1)\n",
        "    shapiro2 = stats.shapiro(group2)\n",
        "    print(f\"  Disease group: Shapiro-Wilk p = {shapiro1.pvalue:.4f} ({'Normal' if shapiro1.pvalue > 0.05 else 'Non-normal'})\")\n",
        "    print(f\"  No disease group: Shapiro-Wilk p = {shapiro2.pvalue:.4f} ({'Normal' if shapiro2.pvalue > 0.05 else 'Non-normal'})\")\n",
        "\n",
        "    # Check homogeneity of variance\n",
        "    levene = stats.levene(group1, group2)\n",
        "    print(f\"\\nHomogeneity of Variance:\")\n",
        "    print(f\"  Levene's test p = {levene.pvalue:.4f} ({'Equal variances' if levene.pvalue > 0.05 else 'Unequal variances'})\")\n",
        "\n",
        "    # Perform independent t-test\n",
        "    ttest = stats.ttest_ind(group1, group2, equal_var=(levene.pvalue > 0.05))\n",
        "\n",
        "    # Calculate Cohen's d for t-test\n",
        "    n1, n2 = len(group1), len(group2)\n",
        "    mean1, mean2 = group1.mean(), group2.mean()\n",
        "    std1, std2 = group1.std(), group2.std()\n",
        "\n",
        "    if levene.pvalue > 0.05:\n",
        "        # Pooled standard deviation\n",
        "        s_pooled = np.sqrt(((n1 - 1) * std1**2 + (n2 - 1) * std2**2) / (n1 + n2 - 2))\n",
        "        d = abs(mean1 - mean2) / s_pooled\n",
        "    else:\n",
        "        # For Welch's t-test, use average standard deviation\n",
        "        d = abs(mean1 - mean2) / np.sqrt((std1**2 + std2**2) / 2)\n",
        "\n",
        "    # Perform Mann-Whitney U test\n",
        "    mwu = mannwhitneyu(group1, group2, alternative='two-sided')\n",
        "\n",
        "    # Calculate effect size r for Mann-Whitney U test\n",
        "    n_total = n1 + n2\n",
        "    mean_u = (n1 * n2) / 2\n",
        "    std_u = np.sqrt((n1 * n2 * (n1 + n2 + 1)) / 12)\n",
        "    z_score = (mwu.statistic - mean_u) / std_u\n",
        "    r = abs(z_score) / np.sqrt(n_total)\n",
        "\n",
        "    # Print results\n",
        "    print(\"\\nParametric Test (t-test):\")\n",
        "    print(f\"  t = {ttest.statistic:.4f}, p = {ttest.pvalue:.6f}\")\n",
        "    print(f\"  Effect size (Cohen's d) = {d:.4f}\")\n",
        "    print(f\"  Result: {'Significant' if ttest.pvalue < 0.05 else 'Not significant'}\")\n",
        "\n",
        "    print(\"\\nNon-parametric Test (Mann-Whitney U):\")\n",
        "    print(f\"  U = {mwu.statistic:.4f}, p = {mwu.pvalue:.6f}\")\n",
        "    print(f\"  Effect size (r) = {r:.4f}\")\n",
        "    print(f\"  Result: {'Significant' if mwu.pvalue < 0.05 else 'Not significant'}\")\n",
        "\n",
        "    # Compare results\n",
        "    print(\"\\nComparison:\")\n",
        "    if (ttest.pvalue < 0.05) == (mwu.pvalue < 0.05):\n",
        "        print(\"  Both tests lead to the same conclusion regarding statistical significance.\")\n",
        "\n",
        "        if abs(ttest.pvalue - mwu.pvalue) < 0.01:\n",
        "            print(\"  The p-values are very similar.\")\n",
        "        elif ttest.pvalue < mwu.pvalue:\n",
        "            print(\"  The t-test produced a smaller p-value (more significant result).\")\n",
        "        else:\n",
        "            print(\"  The Mann-Whitney U test produced a smaller p-value (more significant result).\")\n",
        "    else:\n",
        "        print(\"  The tests lead to DIFFERENT conclusions regarding statistical significance!\")\n",
        "        print(\"  This discrepancy often occurs when parametric assumptions are violated.\")\n",
        "\n",
        "        if shapiro1.pvalue < 0.05 or shapiro2.pvalue < 0.05:\n",
        "            print(\"  Since the normality assumption is violated, the Mann-Whitney U test result is more reliable.\")\n",
        "        elif levene.pvalue < 0.05:\n",
        "            print(\"  Since the equal variance assumption is violated, the t-test with Welch's correction or Mann-Whitney U test may be more appropriate.\")\n",
        "\n",
        "    # Return results for further analysis\n",
        "    return {\n",
        "        'ttest_statistic': ttest.statistic,\n",
        "        'ttest_pvalue': ttest.pvalue,\n",
        "        'cohens_d': d,\n",
        "        'mwu_statistic': mwu.statistic,\n",
        "        'mwu_pvalue': mwu.pvalue,\n",
        "        'effect_size_r': r,\n",
        "        'normality1': shapiro1.pvalue > 0.05,\n",
        "        'normality2': shapiro2.pvalue > 0.05,\n",
        "        'equal_variance': levene.pvalue > 0.05\n",
        "    }\n",
        "\n",
        "# Compare parametric and non-parametric test results for our key variables\n",
        "print(\"\\n\\nComparing Parametric (t-test) and Non-parametric (Mann-Whitney U) Test Results:\")\n",
        "\n",
        "# Compare results for age\n",
        "age_comparison = compare_parametric_nonparametric('age', 'Age (years)')\n",
        "\n",
        "# Compare results for cholesterol\n",
        "chol_comparison = compare_parametric_nonparametric('chol', 'Cholesterol (mg/dl)')\n",
        "\n",
        "# Compare results for maximum heart rate\n",
        "hr_comparison = compare_parametric_nonparametric('thalach', 'Maximum Heart Rate')\n",
        "\n",
        "# Compare results for ST depression induced by exercise (oldpeak)\n",
        "oldpeak_comparison = compare_parametric_nonparametric('oldpeak', 'ST Depression')"
      ],
      "metadata": {
        "id": "ARQZZn5JuVuh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. Comparing Paired Test Results\n",
        "\n",
        "Now let's compare the results from the paired parametric test (paired t-test) with its non-parametric alternatives (Wilcoxon signed-rank test and sign test) using our simulated blood pressure data.\n"
      ],
      "metadata": {
        "id": "RNDdkog58Mei"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def compare_paired_tests(before_data, after_data, var_name, display_name=None):\n",
        "\n",
        "    if display_name is None:\n",
        "        display_name = var_name\n",
        "\n",
        "    print(f\"\\nComparing Paired Tests for {display_name}:\")\n",
        "\n",
        "    # Calculate differences\n",
        "    diff = after_data - before_data\n",
        "\n",
        "    # Check normality of differences (key assumption for paired t-test)\n",
        "    shapiro = stats.shapiro(diff)\n",
        "    print(\"\\nNormality Check for Differences:\")\n",
        "    print(f\"  Shapiro-Wilk p = {shapiro.pvalue:.4f} ({'Normal' if shapiro.pvalue > 0.05 else 'Non-normal'})\")\n",
        "\n",
        "    # Check symmetry of differences (key assumption for Wilcoxon signed-rank test)\n",
        "    median_diff = np.median(diff)\n",
        "    distances = np.abs(diff - median_diff)\n",
        "    above_median = distances[diff > median_diff]\n",
        "    below_median = distances[diff < median_diff]\n",
        "\n",
        "    if len(above_median) > 0 and len(below_median) > 0:\n",
        "        ks = stats.ks_2samp(above_median, below_median)\n",
        "        print(\"\\nSymmetry Check for Differences:\")\n",
        "        print(f\"  Kolmogorov-Smirnov p = {ks.pvalue:.4f} ({'Symmetric' if ks.pvalue > 0.05 else 'Asymmetric'})\")\n",
        "    else:\n",
        "        print(\"\\nCannot check symmetry: too many identical values.\")\n",
        "\n",
        "    # Calculate descriptive statistics\n",
        "    n = len(before_data)\n",
        "    mean_before, mean_after = np.mean(before_data), np.mean(after_data)\n",
        "    median_before, median_after = np.median(before_data), np.median(after_data)\n",
        "    std_before, std_after = np.std(before_data, ddof=1), np.std(after_data, ddof=1)\n",
        "    mean_diff = mean_after - mean_before\n",
        "    median_diff = median_after - median_before\n",
        "    std_diff = np.std(diff, ddof=1)\n",
        "\n",
        "    # 1. Paired t-test\n",
        "    ttest = stats.ttest_rel(before_data, after_data)\n",
        "\n",
        "    # Calculate Cohen's d for paired t-test\n",
        "    d = mean_diff / std_diff\n",
        "\n",
        "    # 2. Wilcoxon signed-rank test\n",
        "    try:\n",
        "        wilcoxon_result = stats.wilcoxon(before_data, after_data)\n",
        "\n",
        "        # Calculate effect size r for Wilcoxon test\n",
        "        non_zero_diff = diff[diff != 0]\n",
        "        n_nonzero = len(non_zero_diff)\n",
        "        z = (wilcoxon_result.statistic - (n_nonzero * (n_nonzero + 1)) / 4) / np.sqrt((n_nonzero * (n_nonzero + 1) * (2 * n_nonzero + 1)) / 24)\n",
        "        wilcoxon_r = abs(z) / np.sqrt(n)\n",
        "    except Exception as e:\n",
        "        print(f\"Error performing Wilcoxon test: {e}\")\n",
        "        wilcoxon_result = None\n",
        "        wilcoxon_r = None\n",
        "\n",
        "    # 3. Sign test\n",
        "    pos_count = np.sum(diff > 0)\n",
        "    neg_count = np.sum(diff < 0)\n",
        "    zero_count = np.sum(diff == 0)\n",
        "    n_nonzero = pos_count + neg_count\n",
        "\n",
        "    if n_nonzero > 0:\n",
        "        sign_test = binomtest(pos_count, n_nonzero, p=0.5)\n",
        "\n",
        "        # Calculate effect size g for sign test\n",
        "        proportion = pos_count / n_nonzero\n",
        "        g = abs(proportion - 0.5) / 0.5\n",
        "    else:\n",
        "        sign_test = None\n",
        "        g = None\n",
        "\n",
        "    # Print results\n",
        "    print(\"\\nDescriptive Statistics:\")\n",
        "    print(f\"  Before: Mean = {mean_before:.2f}, Median = {median_before:.2f}, SD = {std_before:.2f}\")\n",
        "    print(f\"  After: Mean = {mean_after:.2f}, Median = {median_after:.2f}, SD = {std_after:.2f}\")\n",
        "    print(f\"  Mean difference = {mean_diff:.2f}, Median difference = {median_diff:.2f}, SD of differences = {std_diff:.2f}\")\n",
        "\n",
        "    print(\"\\n1. Parametric Test (Paired t-test):\")\n",
        "    print(f\"  t = {ttest.statistic:.4f}, p = {ttest.pvalue:.6f}\")\n",
        "    print(f\"  Effect size (Cohen's d) = {d:.4f}\")\n",
        "    print(f\"  Result: {'Significant' if ttest.pvalue < 0.05 else 'Not significant'}\")\n",
        "\n",
        "    if wilcoxon_result is not None:\n",
        "        print(\"\\n2. Non-parametric Test (Wilcoxon Signed-Rank Test):\")\n",
        "        print(f\"  W = {wilcoxon_result.statistic:.4f}, p = {wilcoxon_result.pvalue:.6f}\")\n",
        "        print(f\"  Effect size (r) = {wilcoxon_r:.4f}\")\n",
        "        print(f\"  Result: {'Significant' if wilcoxon_result.pvalue < 0.05 else 'Not significant'}\")\n",
        "\n",
        "    if sign_test is not None:\n",
        "        print(\"\\n3. Non-parametric Test (Sign Test):\")\n",
        "        print(f\"  Positive differences = {pos_count}, Negative differences = {neg_count}, No change = {zero_count}\")\n",
        "        print(f\"  p = {sign_test.pvalue:.6f}\")\n",
        "        print(f\"  Effect size (g) = {g:.4f}\")\n",
        "        print(f\"  Result: {'Significant' if sign_test.pvalue < 0.05 else 'Not significant'}\")\n",
        "\n",
        "    # Compare results\n",
        "    print(\"\\nComparison:\")\n",
        "\n",
        "    # Create a list of tests with valid results\n",
        "    tests = []\n",
        "    if ttest is not None:\n",
        "        tests.append(('Paired t-test', ttest.pvalue < 0.05))\n",
        "    if wilcoxon_result is not None:\n",
        "        tests.append(('Wilcoxon test', wilcoxon_result.pvalue < 0.05))\n",
        "    if sign_test is not None:\n",
        "        tests.append(('Sign test', sign_test.pvalue < 0.05))\n",
        "\n",
        "    # Check if all tests agree on significance\n",
        "    all_agree = all(result == tests[0][1] for _, result in tests)\n",
        "\n",
        "    if all_agree:\n",
        "        print(f\"  All tests agree: The effect is {'significant' if tests[0][1] else 'not significant'}.\")\n",
        "    else:\n",
        "        print(\"  The tests disagree on statistical significance.\")\n",
        "\n",
        "        # List which tests found significance\n",
        "        significant_tests = [name for name, result in tests if result]\n",
        "        non_significant_tests = [name for name, result in tests if not result]\n",
        "\n",
        "        if significant_tests:\n",
        "            print(f\"  Significant results from: {', '.join(significant_tests)}\")\n",
        "        if non_significant_tests:\n",
        "            print(f\"  Non-significant results from: {', '.join(non_significant_tests)}\")\n",
        "\n",
        "        if shapiro.pvalue < 0.05:\n",
        "            print(\"  Since the normality assumption is violated, the non-parametric test results are more reliable.\")\n",
        "        else:\n",
        "            print(\"  The differences appear normally distributed, so the paired t-test may be most appropriate.\")\n",
        "\n",
        "    # Create visualizations to compare the test results\n",
        "    plt.figure(figsize=(15, 10))\n",
        "\n",
        "    # 1. Histogram of differences with test results\n",
        "    plt.subplot(2, 2, 1)\n",
        "    sns.histplot(diff, kde=True)\n",
        "    plt.axvline(0, color='k', linestyle='--', label='No Difference')\n",
        "    plt.axvline(mean_diff, color='r', linestyle='-', label=f'Mean Diff: {mean_diff:.2f}')\n",
        "    plt.axvline(median_diff, color='g', linestyle='-', label=f'Median Diff: {median_diff:.2f}')\n",
        "    plt.title('Distribution of Differences')\n",
        "    plt.xlabel('Difference (After - Before)')\n",
        "    plt.legend()\n",
        "\n",
        "    # 2. Q-Q plot of differences (normality check)\n",
        "    plt.subplot(2, 2, 2)\n",
        "    sm.qqplot(diff, line='45', ax=plt.gca())\n",
        "    plt.title('Q-Q Plot of Differences')\n",
        "\n",
        "    # 3. Bar chart comparing p-values\n",
        "    plt.subplot(2, 2, 3)\n",
        "    test_names = []\n",
        "    p_values = []\n",
        "    colors = []\n",
        "\n",
        "    if ttest is not None:\n",
        "        test_names.append('Paired t-test')\n",
        "        p_values.append(ttest.pvalue)\n",
        "        colors.append('blue' if ttest.pvalue < 0.05 else 'gray')\n",
        "\n",
        "    if wilcoxon_result is not None:\n",
        "        test_names.append('Wilcoxon')\n",
        "        p_values.append(wilcoxon_result.pvalue)\n",
        "        colors.append('blue' if wilcoxon_result.pvalue < 0.05 else 'gray')\n",
        "\n",
        "    if sign_test is not None:\n",
        "        test_names.append('Sign test')\n",
        "        p_values.append(sign_test.pvalue)\n",
        "        colors.append('blue' if sign_test.pvalue < 0.05 else 'gray')\n",
        "\n",
        "    plt.bar(test_names, p_values, color=colors)\n",
        "    plt.axhline(0.05, color='r', linestyle='--', label='α = 0.05')\n",
        "    plt.title('P-values by Test')\n",
        "    plt.ylabel('P-value')\n",
        "    plt.ylim(0, max(max(p_values) + 0.01, 0.06))  # Set y-limit to show alpha line\n",
        "\n",
        "    for i, p in enumerate(p_values):\n",
        "        plt.text(i, p + 0.005, f'{p:.4f}', ha='center')\n",
        "\n",
        "    plt.legend()\n",
        "\n",
        "    # 4. Bar chart comparing effect sizes\n",
        "    plt.subplot(2, 2, 4)\n",
        "    effect_names = []\n",
        "    effect_sizes = []\n",
        "\n",
        "    if d is not None:\n",
        "        effect_names.append(\"Cohen's d\")\n",
        "        effect_sizes.append(abs(d))\n",
        "\n",
        "    if wilcoxon_r is not None:\n",
        "        effect_names.append(\"Wilcoxon r\")\n",
        "        effect_sizes.append(wilcoxon_r)\n",
        "\n",
        "    if g is not None:\n",
        "        effect_names.append(\"Sign test g\")\n",
        "        effect_sizes.append(g)\n",
        "\n",
        "    plt.bar(effect_names, effect_sizes)\n",
        "    plt.title('Effect Sizes by Test')\n",
        "    plt.ylabel('Effect Size')\n",
        "\n",
        "    for i, e in enumerate(effect_sizes):\n",
        "        plt.text(i, e + 0.02, f'{e:.4f}', ha='center')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.suptitle(f'Comparison of Paired Tests for {display_name}', fontsize=16, y=1.02)\n",
        "    plt.show()\n",
        "\n",
        "    # Return results for further analysis if needed\n",
        "    return {\n",
        "        'ttest_statistic': ttest.statistic if ttest is not None else None,\n",
        "        'ttest_pvalue': ttest.pvalue if ttest is not None else None,\n",
        "        'cohens_d': d,\n",
        "        'wilcoxon_statistic': wilcoxon_result.statistic if wilcoxon_result is not None else None,\n",
        "        'wilcoxon_pvalue': wilcoxon_result.pvalue if wilcoxon_result is not None else None,\n",
        "        'effect_size_r': wilcoxon_r,\n",
        "        'sign_test_pvalue': sign_test.pvalue if sign_test is not None else None,\n",
        "        'effect_size_g': g,\n",
        "        'normality': shapiro.pvalue > 0.05\n",
        "    }\n",
        "\n",
        "# Compare paired test results for our simulated blood pressure data\n",
        "print(\"\\n\\nComparing Paired Parametric and Non-parametric Test Results:\")\n",
        "\n",
        "# Scenario 1: Moderate effect\n",
        "print(\"\\n=== Scenario 1: Moderate Treatment Effect ===\")\n",
        "moderate_comparison = compare_paired_tests(bp_before1, bp_after1, 'blood_pressure', 'Blood Pressure (mmHg) - Moderate Effect')\n",
        "\n",
        "# Scenario 2: Small effect\n",
        "print(\"\\n=== Scenario 2: Small Treatment Effect ===\")\n",
        "small_comparison = compare_paired_tests(bp_before2, bp_after2, 'blood_pressure', 'Blood Pressure (mmHg) - Small Effect')\n",
        "\n"
      ],
      "metadata": {
        "id": "RJBgC0rxuysI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import f\n",
        "\n",
        "f_stat = 25.33\n",
        "df1 = 2\n",
        "df2 = 6\n",
        "\n",
        "p_value = 1 - f.cdf(f_stat, df1, df2)\n",
        "print(f\"p-value: {p_value:.4f}\")\n"
      ],
      "metadata": {
        "id": "0zzoVssxoP7p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ez8xknoo8ZqS"
      }
    }
  ]
}